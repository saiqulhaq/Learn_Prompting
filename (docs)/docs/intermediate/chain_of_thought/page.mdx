export const metadata = {
  sidebar_position: 3,
  title: "ðŸŸ¢ Chain of Thought Prompting",
  description: "Dive into the online guide about Chain of Thought examples. Enhance your engineering skills with AI in this course at Learn Prompting. Start now!",
};

# ðŸŸ¢ Chain of Thought Prompting

## What is Chain of Thought Prompting?

Chain of thought (CoT) prompting (@wei2022chain) is a recent advancement in prompting methods 
that encourage Large Language Models (LLMs) to explain their reasoning. 
This method contrasts with standard prompting by not only seeking an answer 
but also requiring the model to explain its steps to arrive at that answer. 

The below image(@wei2022chain) shows a <Term term="few shot standard prompt">
few shot standard prompt</Term> (left) compared to a chain of thought prompt (right). This comparison between a few-shot standard prompt and a chain-of-thought prompt 
illustrates the difference: while the standard approach directly seeks a solution, 
the CoT approach guides the LLM to unfold its reasoning, 
often leading to more accurate and interpretable results. 



<div style={{ textAlign: "center" }}>
  <Image
    src="/docs/assets/basics/chain_of_thought_example.webp"
    width={1788}
    height={900}
    style={{ width: "750px", margin: "auto" }}
  />
</div>

<div style={{ textAlign: "center" }}>Regular Prompting vs CoT (Wei et al.)</div>

The main idea of CoT is that by showing the LLM some few shot <Term term="exemplars">exemplars</Term> where the reasoning
process is explained in the exemplars, the LLM will also show the reasoning process
when answering the prompt. This explanation of reasoning often leads to more accurate
results.

## How to Use Chain-of-Thought Prompting

Here are a few demos. The first shows GPT-3 (davinci-003)
failing to solve a simple word problem. The second shows GPT-3 (davinci-003) succesfully solving the same problem, by using CoT prompting.

#### Incorrect

<iframe
  src="https://embed.learnprompting.org/embed?config=eyJ0b3BQIjowLCJ0ZW1wZXJhdHVyZSI6MCwibWF4VG9rZW5zIjoyNTYsIm91dHB1dCI6Ik9wdGlvbiAxIGlzIGEgZmFzdGVyIHdheSB0byBnZXQgdG8gd29yay4iLCJwcm9tcHQiOiJXaGljaCBpcyBhIGZhc3RlciB3YXkgdG8gZ2V0IHRvIHdvcms%2FXG5PcHRpb24gMTogVGFrZSBhIDEwMDAgbWludXRlIGJ1cywgdGhlbiBhIGhhbGYgaG91ciB0cmFpbiwgYW5kIGZpbmFsbHkgYSAxMCBtaW51dGUgYmlrZSByaWRlLlxuT3B0aW9uIDI6IFRha2UgYW4gODAwIG1pbnV0ZSBidXMsIHRoZW4gYW4gaG91ciB0cmFpbiwgYW5kIGZpbmFsbHkgYSAzMCBtaW51dGUgYmlrZSByaWRlLiIsIm1vZGVsIjoidGV4dC1kYXZpbmNpLTAwMyJ9"
  style={{
    width: "100%",
    height: "500px",
    border: "0",
    borderRadius: "4px",
    overflow: "hidden",
  }}
  sandbox="allow-forms allow-modals allow-popups allow-presentation allow-same-origin allow-scripts"
></iframe>

#### Correct

<iframe
  src="https://embed.learnprompting.org/embed?config=eyJ0b3BQIjowLCJ0ZW1wZXJhdHVyZSI6MCwibWF4VG9rZW5zIjoyNTYsIm91dHB1dCI6Ik9wdGlvbiAxIHdpbGwgdGFrZSAxMDAwKzMwKzEwID0gMTA0MCBtaW51dGVzLlxuT3B0aW9uIDIgd2lsbCB0YWtlIDgwMCs2MCszMCA9IDg5MCBtaW51dGVzLlxuU2luY2UgT3B0aW9uIDIgdGFrZXMgODkwIG1pbnV0ZXMgYW5kIE9wdGlvbiAxIHRha2VzIDEwNDAgbWludXRlcywgT3B0aW9uIDIgaXMgZmFzdGVyLiIsInByb21wdCI6IldoaWNoIGlzIGEgZmFzdGVyIHdheSB0byBnZXQgaG9tZT9cbk9wdGlvbiAxOiBUYWtlIGFuIDEwIG1pbnV0ZXMgYnVzLCB0aGVuIGFuIDQwIG1pbnV0ZSBidXMsIGFuZCBmaW5hbGx5IGEgMTAgbWludXRlIHRyYWluLlxuT3B0aW9uIDI6IFRha2UgYSA5MCBtaW51dGVzIHRyYWluLCB0aGVuIGEgNDUgbWludXRlIGJpa2UgcmlkZSwgYW5kIGZpbmFsbHkgYSAxMCBtaW51dGUgYnVzLlxuT3B0aW9uIDEgd2lsbCB0YWtlIDEwKzQwKzEwID0gNjAgbWludXRlcy5cbk9wdGlvbiAyIHdpbGwgdGFrZSA5MCs0NSsxMD0xNDUgbWludXRlcy5cblNpbmNlIE9wdGlvbiAxIHRha2VzIDYwIG1pbnV0ZXMgYW5kIE9wdGlvbiAyIHRha2VzIDE0NSBtaW51dGVzLCBPcHRpb24gMSBpcyBmYXN0ZXIuXG5cbldoaWNoIGlzIGEgZmFzdGVyIHdheSB0byBnZXQgdG8gd29yaz9cbk9wdGlvbiAxOiBUYWtlIGEgMTAwMCBtaW51dGUgYnVzLCB0aGVuIGEgaGFsZiBob3VyIHRyYWluLCBhbmQgZmluYWxseSBhIDEwIG1pbnV0ZSBiaWtlIHJpZGUuXG5PcHRpb24gMjogVGFrZSBhbiA4MDAgbWludXRlIGJ1cywgdGhlbiBhbiBob3VyIHRyYWluLCBhbmQgZmluYWxseSBhIDMwIG1pbnV0ZSBiaWtlIHJpZGUuIiwibW9kZWwiOiJ0ZXh0LWRhdmluY2ktMDAzIn0%3D"
  style={{
    width: "100%",
    height: "500px",
    border: "0",
    borderRadius: "4px",
    overflow: "hidden",
  }}
  sandbox="allow-forms allow-modals allow-popups allow-presentation allow-same-origin allow-scripts"
></iframe>

## Chain-of-Thought Results

CoT has been shown to be effective in improving results on tasks like
arithmetic, commonsense, and symbolic reasoning tasks (@wei2022chain).
In particular, prompted PaLM 540B(@chowdhery2022palm) achieves 57% solve
rate accuracy on GSM8K(@cobbe2021training) (SOTA at the time).

<div style={{ textAlign: "center" }}>
  <Image
    src="/docs/assets/intermediate/prompted_palm.webp"
    width={798}
    height={774}
    style={{ width: "300px", margin: "auto" }}
  />
</div>

<div style={{ textAlign: "center" }}>
  Comparison of models on the GSM8K benchmark (Wei et al.)
</div>

## Limitations of Chain-of-Thought

Importantly, according to Wei et al., "CoT only yields performance gains when used with models of âˆ¼100B parameters". Smaller models wrote illogical chains of thought, which led to worse accuracy than standard prompting. Models usually get performance boosts from CoT prompting in a manner proportional to the size of the model.

## Notes

No language models were ~~hurt~~ finetuned in the process of writing this chapter ðŸ˜Š.

## Conclusion

CoT prompting significantly advances how we interact with Large Language Models, offering a method that encourages an articulated reasoning process. 
This approach has improved the accuracy and interpretability of model outputs, particularly in complex reasoning tasks. 
Its effectiveness is more pronounced in larger models, and CoT prompting underscores the potential for 
developing AI systems that provide correct answers and transparent 
insights into their thought processes, bridging the gap between human reasoning and 
artificial intelligence.