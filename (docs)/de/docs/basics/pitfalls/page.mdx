export const metadata = { sidebar_position: 90, title: "üü¢ Fallen der LLMs" };

# üü¢ Fallen der LLMs

<div style={{ textAlign: "center" }}>
  <Image
    src={"/docs/assets/basics/pitfalls.svg"}
    width={1600}
    height={1019}
    style={{
      width: "100%",
      height: "300px",
      verticalAlign: "top",
      margin: "auto",
    }}
  />
</div>

LLMs sind extrem leistungsf√§hig, aber sie sind keineswegs perfekt. Es gibt viele Fallstricke, auf die du achten solltest, wenn du sie nutzt.

## Citing Sources

LLMs k√∂nnen in den meisten F√§llen **keine genauen Quellenangaben** machen. Das liegt daran, dass sie keinen Zugang zum Internet haben und nicht genau wissen, woher ihre Informationen stammen. Sie erstellen h√§ufig Quellen, die gut aussehen, aber v√∂llig ungenau sind.

<Notice>
  Strategien wie sucherweiterte LLMs (LLMs, die das Internet und andere Quellen
  durchsuchen k√∂nnen) k√∂nnen dieses Problem oft l√∂sen
</Notice>

## Bias

LLMs sind oft geneigt, stereotype Antworten zu geben. Selbst mit Sicherheitsvorkehrungen werden sie manchmal sexistische/rassistische/homophobe Dinge sagen. Sei vorsichtig, wenn du LLMs in verbraucherorientierten Anwendungen verwendest, und sei auch vorsichtig, wenn du sie in der Forschung einsetzt (sie k√∂nnen verzerrte Ergebnisse liefern).

## Halluzinationen

LLMs k√∂nnen Unwahrheiten produzieren, wenn ihnen eine Frage gestellt wird, deren Antwort sie nicht kennen. Manchmal geben sie an, dass sie die Antwort nicht wissen, aber meistens werden sie selbstbewusst eine falsche Antwort geben.

## Mathematik

LLMs sind oft schlecht in Mathe. Sie haben Schwierigkeiten, einfache mathematische Probleme zu l√∂sen. Bei komplexen Aufgaben sind sie oft gar nicht in der Lage diese zu l√∂sen.

<Notice>
  Dieses Problem l√§sst sich bis zu einem gewissen Grad durch die Verwendung
  einer [Werkzeug-erweiterter
  LLM](https://learnprompting.org/docs/advanced_applications/mrkl).
</Notice>

## Prompt Hacking

Benutzer k√∂nnen LLMs dazu bringen, beliebige Inhalte zu erstellen. Mehr dar√ºber kannst du [hier](https://learnprompting.org/docs/category/-prompt-hacking) lesen.
